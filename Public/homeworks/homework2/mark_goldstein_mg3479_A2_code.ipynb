{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "n1rRYMF_okBY"
   },
   "outputs": [],
   "source": [
    "# Import dependencies\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from plot_lib import set_default, show_scatterplot, plot_bases\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YkaTWgU3okBc"
   },
   "outputs": [],
   "source": [
    "# Set up your device \n",
    "cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda:0\" if cuda else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_zcS-H-mokBe"
   },
   "outputs": [],
   "source": [
    "# Set up random seed to 1008. Do not change the random seed.\n",
    "# Yes, these are all necessary when you run experiments!\n",
    "seed = 1008\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "if cuda:\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "64jNfD5UokBh"
   },
   "outputs": [],
   "source": [
    "# Define data generating functions\n",
    "def quadratic_data_generator(data_size):\n",
    "    # f(x) = y = x^2 + 4x - 3\n",
    "    # generate an input tensor of size data_size with torch.randn\n",
    "    x = torch.randn(data_size, 1) - 2   \n",
    "    x = x.to(device)\n",
    "    # TODO\n",
    "    '''\n",
    "    y = ...\n",
    "    '''\n",
    "    # placeholder\n",
    "    y = torch.ones(data_size,1)\n",
    "    return x,y\n",
    "\n",
    "def cubic_data_generator(data_size=100):\n",
    "    # f(x) = y = x^3 + 4x^2 - 3\n",
    "    # generate an input tensor of size data_size with torch.randn\n",
    "    x = torch.randn(data_size, 1) - 2   \n",
    "    x = x.to(device)\n",
    "    # TODO\n",
    "    '''\n",
    "    y = ...\n",
    "    '''\n",
    "    # placeholder\n",
    "    y = torch.ones(data_size,1)\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_zcCkt40okBj"
   },
   "outputs": [],
   "source": [
    "# Generate the data with 128 datapoints\n",
    "x, y = quadratic_data_generator(128)\n",
    "plt.scatter(x,y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rn1TqPoHokBt"
   },
   "outputs": [],
   "source": [
    "# Define a Linear Classifier with a single linear layer and no non-linearity\n",
    "# (no hidden layer)\n",
    "class Linear_0H(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        # TODO\n",
    "        self.classifer = None\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.classifier(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "In6FSCPzokBv"
   },
   "outputs": [],
   "source": [
    "# Define a Linear Classifier with a single hidden layer of size 5 and ReLU non-linearity\n",
    "class Linear_1H(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        # TODO\n",
    "        self.classifer = None\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.classifier(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pzRNs4M1okBx"
   },
   "outputs": [],
   "source": [
    "# Define a Linear Classifier with a two hidden layers of size 5 and ReLU non-linearity\n",
    "class Linear_2H(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        # TODO\n",
    "        self.classifer = None\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.classifier(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "M_vRsu4BokBz"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "TODO: Training function\n",
    "\n",
    "Hint: look at some example pytorch tutorials to learn how to\n",
    "    - initialize optimizers\n",
    "    - zero gradient\n",
    "    - backprop the loss\n",
    "    - step the gradient\n",
    "\n",
    "\n",
    "Note: This is full batch. We compute forward on whole x,y.\n",
    "No need for dataloaders nor loop over batches. \n",
    "Just pass all of x to model's forward pass.\n",
    "'''\n",
    "def train(model, epochs, x, y):\n",
    "    \n",
    "    # Set model to training mode\n",
    "    model.train()\n",
    "    \n",
    "    # Define MSE loss function\n",
    "    criterion = None\n",
    "    \n",
    "    # TODO: Define the SGD optimizer with learning rate 0.01\n",
    "    optimizer = None\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        \n",
    "        # TODO: Forward data through model to predict y\n",
    "        y_pred = None\n",
    "        \n",
    "        # TODO: Compute loss in terms of predicted and true y\n",
    "        loss = None\n",
    "\n",
    "        # TODO: Zero gradient\n",
    "        \n",
    "        # TODO: call backward on loss\n",
    "        \n",
    "        # TODO: step the optimizer\n",
    "        \n",
    "        # every 100 epochs, print\n",
    "        if (epoch+1) % 100 == 0:\n",
    "            print('Epoch {} loss: {}'.format(epoch+1, loss.item()))\n",
    "            \n",
    "    # return y_pred without gradient information, for plotting\n",
    "    return y_pred.detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lx_EMETookB1",
    "outputId": "91eb5402-4009-437b-a601-ff6b73dcd5d7"
   },
   "outputs": [],
   "source": [
    "# 0H model on quadratic data\n",
    "model = Linear_0H()\n",
    "y_pred = train(model, epochs=1000, x=x, y=y)\n",
    "\n",
    "# Plot predictions vs actual data\n",
    "plt.scatter(x, y)\n",
    "plt.scatter(x, y_pred)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "m6HIEi6fokB-",
    "outputId": "74b3a7ef-1cc1-4629-e6ec-fb0594a1cb98"
   },
   "outputs": [],
   "source": [
    "# 1H model on quadratic data\n",
    "model = Linear_1H()\n",
    "y_pred = train(model, epochs=1000, x=x, y=y)\n",
    "plt.scatter(x, y)\n",
    "plt.scatter(x, y_pred)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_j-_jgS2okCC",
    "outputId": "9319d725-cb7c-4c39-f3fe-d80e1577e150"
   },
   "outputs": [],
   "source": [
    "# 2H model on quadratic data\n",
    "model = Linear_2H()\n",
    "y_pred = train(model, epochs=1000, x=x, y=y)\n",
    "plt.scatter(x, y)\n",
    "plt.scatter(x, y_pred)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "e6P6Ta2ookCF"
   },
   "outputs": [],
   "source": [
    "# Generate cubic data with 128 data points\n",
    "x, y = cubic_data_generator(128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JPGQsaiVokCI",
    "outputId": "074f4aa8-d004-4b76-ccd6-73e230e717f9"
   },
   "outputs": [],
   "source": [
    "# 0H model on cubic data\n",
    "model = Linear_0H()\n",
    "y_pred = train(model, epochs=1000, x=x, y=y)\n",
    "plt.scatter(x, y)\n",
    "plt.scatter(x, y_pred)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "68JxHOz8okCL",
    "outputId": "92564c1f-b02f-4e2d-ec15-3177a63733ee"
   },
   "outputs": [],
   "source": [
    "# 1H model on cubic data\n",
    "model = Linear_1H()\n",
    "y_pred = train(model, epochs=1000, x=x, y=y)\n",
    "plt.scatter(x, y)\n",
    "plt.scatter(x, y_pred)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zQCOjn_AokCP",
    "outputId": "822feb80-83b1-4a20-9fb4-776a69655cc5"
   },
   "outputs": [],
   "source": [
    "# 2H model on cubic data\n",
    "model = Linear_2H()\n",
    "y_pred = train(model, epochs=1000, x=x, y=y)\n",
    "plt.scatter(x, y)\n",
    "plt.scatter(x, y_pred)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "DS-GA-1008-HW_assignment_2_master.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
