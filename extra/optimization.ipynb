{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-7jtqlF8YFU7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.5   -0.475 -0.45  ...  1.425  1.45   1.475]\n",
      " [-0.5   -0.475 -0.45  ...  1.425  1.45   1.475]\n",
      " [-0.5   -0.475 -0.45  ...  1.425  1.45   1.475]\n",
      " ...\n",
      " [-0.5   -0.475 -0.45  ...  1.425  1.45   1.475]\n",
      " [-0.5   -0.475 -0.45  ...  1.425  1.45   1.475]\n",
      " [-0.5   -0.475 -0.45  ...  1.425  1.45   1.475]]\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import torch\n",
    "from utils.optim import Optim, output, w"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bt6sbhvuOzb-"
   },
   "source": [
    "# SGD Optimizer\n",
    "\n",
    "In this exercise we try to implement the vanilla SGD optimzation algorithm over a mini batch of data points. Recall that the equation for vanilla SGD was as follows:\n",
    "\n",
    "$$\n",
    "w_i = w_i - \\frac{\\partial{C}}{\\partial{w_i}} * lr\n",
    "$$\n",
    "\n",
    "Where $C$ is the cost function and $lr$ is the learning rate.\n",
    "\n",
    "In the below class, complete the ``` my_step()``` function, both $\\frac{\\partial{C}}{\\partial{w_i}}$ and $lr$ are given to you. \n",
    "\n",
    "Hint: You can access $w_i$ through ```p.data``` and can use the [``` x.add_```](https://pytorch.org/docs/stable/tensors.html?highlight=add_#torch.Tensor.add_) function to perform the addition inplace !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qL1hj2XLO9rx"
   },
   "outputs": [],
   "source": [
    "class SGDOptimizer(Optim):\n",
    "    def __init__(self, params, lr):\n",
    "        defaults = dict(lr=lr)\n",
    "        super(SGDOptimizer, self).__init__(params, defaults)\n",
    "\n",
    "    def my_step(self, p, state, group):\n",
    "        lr = group['lr']\n",
    "        d_p = p.grad.data\n",
    "        p.data.add_(-group['lr'], d_p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bnvBpqL8QY30"
   },
   "source": [
    "Once, that's done we can try to visualise how optimzation is taking place by optimizing over a quadratic function as shown in lecture.\n",
    "\n",
    "We see a lot of variance in the direction of the optimzation if we use a large learning rate and an inability to effectively minimise the function if we use a small learning rate !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 731
    },
    "colab_type": "code",
    "id": "p1gkP9nzb6ae",
    "outputId": "89319756-98cb-4163-cea1-498ab36d3926"
   },
   "outputs": [],
   "source": [
    "output(SGDOptimizer([w], lr=0.33333), fname=\"sgd_lr_opt_example.pdf\")\n",
    "output(SGDOptimizer([w], lr=0.1), fname=\"sgd_lr_good_example.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9oNyEHXyQ23T"
   },
   "source": [
    "# Momentum\n",
    "\n",
    "We can slightly fix the above problems by adding Momentum to our Optimizer. \n",
    "\n",
    "Recall from the lecture that Momentum add's a certain \"force\" to the direction we were travelling in before. Intuitively, from a physics perspective our optimizer has a certain momentum built in when travelling through our scary loss landscape. The benefits of momentum are as follows:\n",
    "\n",
    "1. Accelerates Optimization. Emphirically this has been observed when we train neural networks. However, no **theory** confirms this. We can however theoretically confirm this for quadratics.\n",
    "2. Noise Smoothning. Momentum can help skip over local minima and help aboid the draqstic direction changes as we had seen in vanilla SGD.\n",
    "\n",
    "Recall the equation for SGD + Momentum was given by:\n",
    "\n",
    "$$\n",
    "v_{t+1, i} = \\beta*v_{t,i} + \\frac{\\partial{C}}{\\partial{w_{t,i}}}\n",
    "$$\n",
    "\n",
    "Here, $\\beta$ is a hyperparamter we have to tune. A popular choice of $\\beta$ is 0.9 which intuitively says that we care more about the past directions of the gradient than the direction indicated in the current step. Using $v_i$, our weight update step becomes as follows:\n",
    "$$\n",
    "w_{t+1,i} = w_{t,i} - v_{t+1,i} * lr\n",
    "$$\n",
    "\n",
    "\n",
    "**Note**: $v_{t, i}$ for $t = 0$ is 0.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sEr15GJ3ZC7i"
   },
   "outputs": [],
   "source": [
    "class SGDMomentumOptimizer(Optim):\n",
    "   \n",
    "    def __init__(self, params, lr, momentum):\n",
    "        defaults = dict(lr=lr,momentum=momentum)\n",
    "        super(SGDMomentumOptimizer, self).__init__(params, defaults)\n",
    "\n",
    "    def my_step(self, p, state, group):\n",
    "        lr = group['lr']\n",
    "        momentum = group['momentum']\n",
    "        d_p = p.grad.data\n",
    "        \n",
    "        if 'v' not in state:\n",
    "            state['v'] = torch.clone(d_p).detach()\n",
    "        else:\n",
    "            state['v'] = d_p + momentum*state['v']\n",
    "\n",
    "        d_p = state['v']\n",
    "        p.data.add_(-group['lr']*d_p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jt462ngbWRH9"
   },
   "source": [
    "Let's visualise the performance of this optimizer below. We see that SGD + momentum can perform  better after tuning the learning rate and momentum !\n",
    "\n",
    "An important point to consider when measuring the effect of momentum is to change the learning rate by a similiar amount. This can be achieved by something like this:\n",
    "\n",
    "$$\n",
    "lr_{new} = lr_{old} * (1 - m)\n",
    "$$\n",
    "\n",
    "Unfortunately, tuning these hyper params is a real part of training neural nets effectively :("
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "n9eN7lQFcKLL",
    "outputId": "e94cc645-f3d8-4891-f579-f4bf6b69d2f9"
   },
   "outputs": [],
   "source": [
    "output(SGDMomentumOptimizer([w], lr=0.15*(1-0.5), momentum=0.5), nsteps=10, fname=\"sgd_50mom_example.pdf\")\n",
    "output(SGDMomentumOptimizer([w], lr=0.15*(1-0.25), momentum=0.25), nsteps=10, fname=\"sgd_25mom_example.pdf\")\n",
    "output(SGDMomentumOptimizer([w], lr=0.15*(1-0.75), momentum=0.75), nsteps=10, fname=\"sgd_75mom_example.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "71AW8tPCXaBN"
   },
   "source": [
    "In the below example, we can see a much obvious positive effect of using momentum if we inject noise (increase non convexity) in our loss landscape. Momentum is able to ignore this noise more effectively than vanilla SGD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 748
    },
    "colab_type": "code",
    "id": "c2ATfhURcufu",
    "outputId": "32fce40c-0c5e-4dc5-d426-84ef30cc2196"
   },
   "outputs": [],
   "source": [
    "output(SGDMomentumOptimizer([w], lr=0.1, momentum=0.0), nsteps=30, noise=1.0, fname=\"sgd_noise_example.pdf\")\n",
    "output(SGDMomentumOptimizer([w], lr=0.1*(1-0.8), momentum=0.8), nsteps=30, noise=1.0, fname=\"sgd_mom_noise_example.pdf\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1sE4L-OyY03A"
   },
   "source": [
    "# RMSProp\n",
    "\n",
    "Now, we shall move into the realm of adaptive optimizers that try to do something clever by taking into account the past movement of the gradient for each weight. \n",
    "\n",
    "The intuition is that different layers of a neural network learn at different rates. For example, for a big convolutional net, the output is less sensitive to the pertubations of the weights of the earlier layers and more sensitive to pertubations to the weights of the later layers.\n",
    "\n",
    "Therefore, in some networks using a larger learning rate for earlier layers and a smaller learning rate for later layers could aid in faster and better convergence. \n",
    "\n",
    "One such idea to vary the learning rate is introduced by RMSProp. The key ideas was to normalise the learning rate of each weight by the gradients **Root Mean Square**.\n",
    "\n",
    "$$\n",
    "v_{t+1, i} = \\alpha * v_{t,i} + (1 - \\alpha) * (\\frac{\\partial{C}}{\\partial{w_{t,i}}})^2\n",
    "$$\n",
    "Here, $v$ is simply the *moving average* of the root mean square of the gradient. We use $v$ in our gradient update rule as follows:\n",
    "$$\n",
    "w_{t+1,i} = w_{t, i} - \\frac{lr}{\\sqrt{v_{t+1,i}} + \\epsilon}\n",
    "$$\n",
    "\n",
    "\n",
    "**Hint:** Use the state dictionary to hold the buffers for $v$. Keep in mind that originally the value of v should be 0 and the tensor should be the same shape as that of ```p.grad```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mm6HE3kNZtO-"
   },
   "outputs": [],
   "source": [
    "class RMSPropOptimizer(Optim):\n",
    "   \n",
    "    def __init__(self, params, lr, alpha):\n",
    "        self.eps = 1e-8\n",
    "        defaults = dict(lr=lr,alpha=alpha)\n",
    "        super(RMSPropOptimizer, self).__init__(params, defaults)\n",
    "\n",
    "    def my_step(self, p, state, group):\n",
    "        lr = group['lr']\n",
    "        alpha = group['alpha']\n",
    "        grad = p.grad.data\n",
    "        \n",
    "        if 'v' not in state:\n",
    "            state['v'] = torch.zeros_like(p.data)\n",
    "\n",
    "        state['v'] = (1-alpha)*torch.pow(grad,2) + alpha*state['v']\n",
    "        grad.div_(torch.sqrt(state['v']) + self.eps)\n",
    "        p.data.add_(-group['lr']*grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 374
    },
    "colab_type": "code",
    "id": "FGvndDJ-c2-g",
    "outputId": "0f12938a-2426-4a53-dd6e-49236047ca56"
   },
   "outputs": [],
   "source": [
    "output(RMSPropOptimizer([w], lr=0.1, alpha=0.8), nsteps=30, noise=1.0, fname=\"rmsprop_noise_example.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JOhxGoIXqpkW"
   },
   "source": [
    "# Adam Optimizer\n",
    "\n",
    "What is Adam ? It is simply RMSProp + Momentum.\n",
    "\n",
    "The root mean square term is calculated exactly like as before\n",
    "$$\n",
    "v_{t+1, i} = \\alpha * v_{t,i} + (1 - \\alpha) * (\\frac{\\partial{C}}{\\partial{w_{t,i}}})^2\n",
    "$$\n",
    "The momentum update is given as below, it is roughly equivalent to the momentum in SGD.\n",
    "$$\n",
    "m_{t+1, i} = \\beta * m_{t,i} + (1 - \\beta) * (\\frac{\\partial{C}}{\\partial{w_{t,i}}})\n",
    "$$\n",
    "Finally, the weight update is given as follows:\n",
    "$$\n",
    "w_{t+1,i} = w_{t, i} - \\frac{lr*m}{\\sqrt{v_{t+1,i}} + \\epsilon}\n",
    "$$\n",
    "\n",
    "Is that it ? Well, not quite. Just plugging this in will give us nan values, to correct for this we do something called bias scaling. The idea behind bias scaling is simple. which just keeps the\n",
    "moving averages **unbiased** during early iterations. The algorithm quickly approaches the above steady state form.\n",
    "\n",
    "The equation of Adam with bias scaling is given as follows:\n",
    "\n",
    "$$\n",
    "b_1 = (1 - \\beta)^t\n",
    "$$\n",
    "\n",
    "$$\n",
    "b_2 = (1 - \\alpha)^t\n",
    "$$\n",
    "\n",
    "where $t$ is the step number of the gradient update. We use these values to modify our final weight update as follows:\n",
    "\n",
    "$$\n",
    "w_{t+1,i} = w_{t, i} - lr*\\frac{\\frac{m}{ b_1}}{\\sqrt{\\frac{v_{t+1,i}}{b_2}} + \\epsilon}\n",
    "$$\n",
    "\n",
    "And that's Adam !\n",
    "\n",
    "**Hint:** The torch operator [addcdiv_](https://pytorch.org/docs/stable/tensors.html?highlight=addcdiv_#torch.Tensor.addcdiv_) might be of some interest. Inplace ops are an automatic perf win !\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wBY8z5kVZ7f8"
   },
   "outputs": [],
   "source": [
    "import math \n",
    "\n",
    "class AdamOptimizer(Optim):\n",
    "   \n",
    "    def __init__(self, params, lr, alpha, momentum):\n",
    "        self.eps = 1e-8\n",
    "\n",
    "        defaults = dict(lr=lr, alpha=alpha, momentum=momentum)\n",
    "        super(AdamOptimizer, self).__init__(params, defaults)\n",
    "\n",
    "    def my_step(self, p, state, group):\n",
    "        lr = group['lr']\n",
    "        alpha = group['alpha']\n",
    "        momentum = group['momentum']\n",
    "        grad = p.grad.data\n",
    "\n",
    "        if len(state) == 0:\n",
    "          state['step'] = 0\n",
    "          state['m'] = torch.zeros_like(p.data)\n",
    "          state['v'] = torch.zeros_like(p.data)\n",
    "\n",
    "        state['step'] += 1\n",
    "        m, v = state['m'], state['v']\n",
    "\n",
    "        bias_correction1 = 1 - momentum ** state['step']\n",
    "        bias_correction2 = 1 - alpha ** state['step']\n",
    "\n",
    "        m.mul_(momentum).add_(1 - momentum, grad)\n",
    "\n",
    "        v.mul_(alpha).addcmul_(1 - alpha, grad, grad)\n",
    "\n",
    "        denom = (v.sqrt() / math.sqrt(bias_correction2)).add_(self.eps)\n",
    "        step_size = lr / bias_correction1\n",
    "        p.data.addcdiv_(-step_size, m, denom)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "spCr1Z3ytVrI"
   },
   "source": [
    "As we can see, the updates are much smoother than RMSProp and we get the same benefits of adaptive learning rates !\n",
    "\n",
    "The situation is not as clear when we train deep neural nets. Remember, for some problems a well tuned SGD + Momentum outperforms many of the state of the art optimization techniques :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 374
    },
    "colab_type": "code",
    "id": "5atLfzHMNLMG",
    "outputId": "30f6f9ea-94f9-47e2-c9f4-a8fd1cdd9361"
   },
   "outputs": [],
   "source": [
    "output(AdamOptimizer([w], lr=0.1, alpha=0.7, momentum=0.7), nsteps=30, noise=1.0, fname=\"adam_noise_example.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Final Optimization.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}